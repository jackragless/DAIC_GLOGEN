{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quiet-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpletransformers\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "honest-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jackragless/projects/data/DAIC_GLOGEN/for_ai_training_wgrammar_wpostags_wcrossref.pkl', 'rb') as f:\n",
    "    corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "random-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = int(0.8 * len(corpus))\n",
    "train_data = corpus[:train_cutoff]\n",
    "eval_data = corpus[train_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "industrial-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "balanced-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(\n",
    "    train_data, columns=[\"sentence_id\", \"words\", \"pos\", \"labels\"]\n",
    ")\n",
    "del train_data['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "other-browser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Lumpers</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>splitters</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>are</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>opposing</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28298876</th>\n",
       "      <td>1122605</td>\n",
       "      <td>an</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28298877</th>\n",
       "      <td>1122605</td>\n",
       "      <td>engineer</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28298878</th>\n",
       "      <td>1122605</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28298879</th>\n",
       "      <td>1122605</td>\n",
       "      <td>Apollo</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28298880</th>\n",
       "      <td>1122605</td>\n",
       "      <td>Systems</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28298881 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentence_id      words labels\n",
       "0                   0    Lumpers      B\n",
       "1                   0        and      I\n",
       "2                   0  splitters      I\n",
       "3                   0        are      O\n",
       "4                   0   opposing      O\n",
       "...               ...        ...    ...\n",
       "28298876      1122605         an      O\n",
       "28298877      1122605   engineer      O\n",
       "28298878      1122605        for      O\n",
       "28298879      1122605     Apollo      B\n",
       "28298880      1122605    Systems      I\n",
       "\n",
       "[28298881 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dying-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame(\n",
    "    eval_data, columns=[\"sentence_id\", \"words\", \"pos\", \"labels\"]\n",
    ")\n",
    "del eval_data['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continuous-wheel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1122605</td>\n",
       "      <td>Division</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1122605</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1122605</td>\n",
       "      <td>Hewlett-Packard</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1122605</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1122606</td>\n",
       "      <td>From</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074716</th>\n",
       "      <td>1402309</td>\n",
       "      <td>awards</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074717</th>\n",
       "      <td>1402309</td>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074718</th>\n",
       "      <td>1402309</td>\n",
       "      <td>various</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074719</th>\n",
       "      <td>1402309</td>\n",
       "      <td>publications</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074720</th>\n",
       "      <td>1402309</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7074721 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id            words labels\n",
       "0            1122605         Division      I\n",
       "1            1122605               of      O\n",
       "2            1122605  Hewlett-Packard      B\n",
       "3            1122605                .      O\n",
       "4            1122606             From      O\n",
       "...              ...              ...    ...\n",
       "7074716      1402309           awards      O\n",
       "7074717      1402309             from      O\n",
       "7074718      1402309          various      O\n",
       "7074719      1402309     publications      O\n",
       "7074720      1402309                .      O\n",
       "\n",
       "[7074721 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hollow-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = NERArgs()\n",
    "# model_args.\n",
    "# model_args.evaluate_during_training = True\n",
    "model_args = {\n",
    "    'num_train_epochs': 20,\n",
    "    'train_batch_size' : 32,\n",
    "    'eval_batch_size' : 32,\n",
    "    'evaluate_during_training' : False,\n",
    "    'evaluate_during_training_steps' : -1,\n",
    "    'save_model_every_epoch' : True,\n",
    "    'save_eval_checkpoints' : False,\n",
    "    'save_steps' : -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "honest-indication",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = NERModel(\n",
    "    \"bert\", \"bert-base-cased\", labels= [\"B\", \"I\", \"O\"], use_cuda=True, args = model_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparable-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.ner.ner_model: Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a17d567b9e240ccbc7235a6047ec807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1122606 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 358, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 197, in convert_example_to_feature\n",
      "    word_tokens = tokenizer.tokenize(word)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 250, in tokenize\n",
      "    (str(t), t) for t in self.all_special_tokens_extended if isinstance(t, AddedToken)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 250, in tokenize\n",
      "    (str(t), t) for t in self.all_special_tokens_extended if isinstance(t, AddedToken)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 345, in tokenize\n",
      "    tokenized_text = split_on_tokens(no_split_token, text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 1298, in all_special_tokens_extended\n",
      "    set_attr = self.special_tokens_map_extended\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 1298, in all_special_tokens_extended\n",
      "    set_attr = self.special_tokens_map_extended\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 335, in split_on_tokens\n",
      "    return list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 1272, in special_tokens_map_extended\n",
      "    for attr in self.SPECIAL_TOKENS_ATTRIBUTES:\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 230, in _tokenize\n",
      "    split_tokens += self.wordpiece_tokenizer.tokenize(token)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 338, in <genexpr>\n",
      "    self._tokenize(token) if token not in self.unique_no_split_tokens else [token]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 1273, in special_tokens_map_extended\n",
      "    attr_value = getattr(self, \"_\" + attr)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 230, in _tokenize\n",
      "    split_tokens += self.wordpiece_tokenizer.tokenize(token)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 230, in _tokenize\n",
      "    split_tokens += self.wordpiece_tokenizer.tokenize(token)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 544, in tokenize\n",
      "    if substr in self.vocab:\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 224, in _tokenize\n",
      "    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 395, in tokenize\n",
      "    text = self._clean_text(text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 395, in tokenize\n",
      "    text = self._clean_text(text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 542, in tokenize\n",
      "    if start > 0:\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 415, in tokenize\n",
      "    split_tokens.extend(self._run_split_on_punc(token, never_split))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 395, in tokenize\n",
      "    text = self._clean_text(text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 395, in tokenize\n",
      "    text = self._clean_text(text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 530, in tokenize\n",
      "    if len(chars) > self.max_input_chars_per_word:\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 1285, in all_special_tokens\n",
      "    all_toks = [str(s) for s in self.all_special_tokens_extended]\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 1285, in all_special_tokens\n",
      "    all_toks = [str(s) for s in self.all_special_tokens_extended]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 497, in _clean_text\n",
      "    if _is_whitespace(char):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 404, in tokenize\n",
      "    text = self._tokenize_chinese_chars(text)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 495, in _clean_text\n",
      "    if cp == 0 or cp == 0xFFFD or _is_control(char):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 441, in _run_split_on_punc\n",
      "    if _is_punctuation(char):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 495, in _clean_text\n",
      "    if cp == 0 or cp == 0xFFFD or _is_control(char):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 495, in _clean_text\n",
      "    if cp == 0 or cp == 0xFFFD or _is_control(char):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 1297, in all_special_tokens_extended\n",
      "    all_toks = []\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 1300, in all_special_tokens_extended\n",
      "    all_toks = all_toks + (list(attr_value) if isinstance(attr_value, (list, tuple)) else [attr_value])\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 458, in _tokenize_chinese_chars\n",
      "    if self._is_chinese_char(cp):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 71, in _is_control\n",
      "    cat = unicodedata.category(char)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 57, in _is_whitespace\n",
      "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 86, in _is_punctuation\n",
      "    cat = unicodedata.category(char)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 71, in _is_control\n",
      "    cat = unicodedata.category(char)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\", line 65, in _is_control\n",
      "    def _is_control(char):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\", line 483, in _is_chinese_char\n",
      "    or (cp >= 0xF900 and cp <= 0xFAFF)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO:root:\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 851, in next\n",
      "    item = self._items.popleft()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 341, in convert_examples_to_features\n",
      "    features = list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/tqdm/notebook.py\", line 261, in __iter__\n",
      "    for obj in super(tqdm_notebook, self).__iter__(*args, **kwargs):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/tqdm/std.py\", line 1167, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 420, in <genexpr>\n",
      "    return (item for chunk in result for item in chunk)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 856, in next\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-955efe66ec1c>\", line 1, in <module>\n",
      "    model.train_model(train_data, eval_data=eval_data)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py\", line 324, in train_model\n",
      "    train_dataset = self.load_and_cache_examples(train_data)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py\", line 1217, in load_and_cache_examples\n",
      "    features = convert_examples_to_features(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\", line 341, in convert_examples_to_features\n",
      "    features = list(\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 736, in __exit__\n",
      "    self.terminate()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 654, in terminate\n",
      "    self._terminate()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/multiprocessing/pool.py\", line 717, in _terminate_pool\n",
      "    task_handler.join()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/jackragless/miniconda3/lib/python3.8/posixpath.py\", line 411, in _joinrealpath\n",
      "    name, _, rest = rest.partition(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\u001b[0m in \u001b[0;36mconvert_examples_to_features\u001b[0;34m(examples, label_list, max_seq_length, tokenizer, cls_token_at_end, cls_token, cls_token_segment_id, sep_token, sep_token_extra, pad_on_left, pad_token, pad_token_segment_id, pad_token_label_id, sequence_a_segment_id, mask_padding_with_zero, process_count, chunksize, silent, use_multiprocessing)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             features = list(\n\u001b[0m\u001b[1;32m    342\u001b[0m                 tqdm(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 ))\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-955efe66ec1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[0;34m(self, data, evaluate, no_cache, to_predict)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Converting to features started.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m                 features = convert_examples_to_features(\n\u001b[0m\u001b[1;32m   1218\u001b[0m                     \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/simpletransformers/ner/ner_utils.py\u001b[0m in \u001b[0;36mconvert_examples_to_features\u001b[0;34m(examples, label_list, max_seq_length, tokenizer, cls_token_at_end, cls_token, cls_token_segment_id, sep_token, sep_token_extra, pad_on_left, pad_token, pad_token_segment_id, pad_token_label_id, sequence_a_segment_id, mask_padding_with_zero, process_count, chunksize, silent, use_multiprocessing)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             features = list(\n\u001b[0m\u001b[1;32m    342\u001b[0m                 tqdm(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    223\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, change_notifier, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mtask_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "model.train_model(train_data, eval_data=eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "isolated-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel(\n",
    "    \"bert\", \"/home/jackragless/Downloads/outputs/checkpoint-631476-epoch-18\", use_cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "humanitarian-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.ner.ner_model: Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb5f8add6ce49fabd1f6cfdfa00a8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda13e57649c4e0c9c54b929d2288478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/8741 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.ner.ner_model:{'eval_loss': 0.21615726503650756, 'precision': 0.8544567267964889, 'recall': 0.8808769550884904, 'f1_score': 0.8674657186827512}\n"
     ]
    }
   ],
   "source": [
    "result, model_outputs, preds_list = model.eval_model(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-accounting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
