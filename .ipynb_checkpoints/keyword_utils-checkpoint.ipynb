{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "renewable-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from names_dataset import NameDataset\n",
    "name_dataset = NameDataset()\n",
    "import pandas as pd\n",
    "# unigram = pd.read_csv('/home/jackragless/projects/data/DAIC_GLOGEN/domain_specific_unigram.csv')\n",
    "unigram = pd.read_csv('/home/jackragless/projects/data/DAIC_GLOGEN/unigram_freq.csv')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "received-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chink(kw_arr):\n",
    "    for kw in kw_arr:\n",
    "        if common_word_detect(kw[0]) == True:\n",
    "            kw_arr.remove(kw)\n",
    "#     return kw_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empty-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chink(kw_arr):\n",
    "#     final = []\n",
    "#     for kw in kw_arr:\n",
    "#         if common_word_detect(kw[0]) == True:\n",
    "#             final.append(kw[0] + ' !!!')\n",
    "#         else:\n",
    "#             final.append(kw[0])\n",
    "#     return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "royal-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_detect(candidate_string):\n",
    "    candidate_string = candidate_string.split()\n",
    "    if len(candidate_string) == 2:\n",
    "        if name_dataset.search_first_name(candidate_string[0]) == True and name_dataset.search_last_name(candidate_string[1]) == True:\n",
    "            return True\n",
    "    elif len(candidate_string) == 3:\n",
    "        if name_dataset.search_first_name(candidate_string[0]) == True and len(candidate_string[1])>=2 and candidate_string[1][0].isalpha() and candidate_string[1][1] == '.':\n",
    "            return True\n",
    "        elif name_dataset.search_first_name(candidate_string[0]) == True and name_dataset.search_first_name(candidate_string[1]) and name_dataset.search_last_name(candidate_string[2]) == True:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "public-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_unigram = list(unigram[:10000]['word'])\n",
    "\n",
    "def common_word_detect(candidate_string): #could add stopwords\n",
    "    if candidate_string != candidate_string.upper() and lemmatizer.lemmatize(candidate_string.lower()) in common_unigram:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-growth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
