{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pyfiglet\n",
    "import os\n",
    "import wikipedia\n",
    "from tqdm import tqdm \n",
    "\n",
    "import import_ipynb\n",
    "import preprocess_utils\n",
    "import parse_utils\n",
    "import ai_kw_detect\n",
    "import wikt_def_parse\n",
    "import wikt_def_predict\n",
    "import chink_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = ['Augmented reality-assisted surgery','Universal Scene Description','Junaio','USens','ARCore','Adjusted mutual information','Algorithmic information theory','Anti-information','Ascendency','Asymptotic equipartition property']\n",
    "# for page in pages:\n",
    "#     text_file = open(\"text_files/{}.txt\".format(page), \"w\")\n",
    "#     text_file.write(wikipedia.page(page,auto_suggest=False).content)\n",
    "#     text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_association = {\n",
    "    'CC':['conjunction'],\n",
    "    'CD':['numeral'],\n",
    "    'DT':['determiner'],\n",
    "    'EX':[],\n",
    "    'FW':[],\n",
    "    'IN':['preposition','conjunction'],\n",
    "    'JJ':['adjective'],\n",
    "    'JJR':['adjective'],\n",
    "    'JJS':['adjective'],\n",
    "    'LS':[],\n",
    "    'MD':['verb'],\n",
    "    'NN':['noun','proper noun'],\n",
    "    'NNS':['noun'], #PLURAL\n",
    "    'NNP':['noun', 'proper noun'],\n",
    "    'NNPS':['noun', 'proper noun'], #plural\n",
    "    'PDT':['determiner'],\n",
    "    'POS':[],\n",
    "    'PRP':['pronoun'],\n",
    "    'PRP$':['pronoun'],\n",
    "    'RB':['adverb'],\n",
    "    'RBR':['adverb'],\n",
    "    'RBS':['adverb'],\n",
    "    'RP':['preposition'], #unsure\n",
    "    'TO':[], #unsure\n",
    "    'UH':['interjection'],\n",
    "    'VB':['verb'],\n",
    "    'VBG':['verb'],\n",
    "    'VBD':['verb'],\n",
    "    'VBN':['verb'],\n",
    "    'VBP':['verb'],\n",
    "    'VBZ':['verb'],\n",
    "    'WDT':['determiner'],\n",
    "    'WP':['pronoun'],\n",
    "    'WRB':['adverb'],\n",
    "    #to deal with keyphrases\n",
    "    'noun':['noun', 'proper noun'],\n",
    "    'verb':['verb']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keywords(processed_text):\n",
    "    \n",
    "    candidate_phrases = []\n",
    "    pos = []\n",
    "    tok_sents = []\n",
    "    for sent in nltk.sent_tokenize(processed_text):\n",
    "        temp_tree = parse_utils.parseSent(sent)\n",
    "        if temp_tree:\n",
    "            tok_sents.append(sent[:-1])\n",
    "            candidate_phrases += parse_utils.getPhraseNodes(temp_tree,[])\n",
    "            pos.append( parse_utils.getWordNodes(temp_tree,[]) )\n",
    "        \n",
    "        \n",
    "    pred_kw = ai_kw_detect.predict(tok_sents)\n",
    "    \n",
    "    FINAL_KW = []\n",
    "    kw_only = []\n",
    "    for i in range(len(pred_kw)):\n",
    "        if pred_kw[i]:\n",
    "            for j in range(len(pred_kw[i])):\n",
    "                if pred_kw[i][j].find('.')==-1:\n",
    "                    if len(pred_kw[i][j].split()) == 1:\n",
    "                        for k in range(len(pos[i])):  \n",
    "                            if pred_kw[i][j] == pos[i][k][0] and pred_kw[i][j] not in kw_only:\n",
    "                                FINAL_KW.append([pos[i][k][0], pos_association[pos[i][k][1]]])\n",
    "                                kw_only.append(pos[i][k][0])\n",
    "                                break\n",
    "                    else:\n",
    "                        for m in range(len(candidate_phrases)):\n",
    "\n",
    "                            if pred_kw[i][j] == candidate_phrases[m][0] and pred_kw[i][j] not in kw_only:\n",
    "                                FINAL_KW.append([candidate_phrases[m][0],pos_association[candidate_phrases[m][1]]])\n",
    "                                kw_only.append(candidate_phrases[m][0])\n",
    "                                break\n",
    "                    \n",
    "        \n",
    "    return FINAL_KW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_definitions(title, clean_text, keyword_arr):\n",
    "    final = []\n",
    "    count = 0\n",
    "    for kw in tqdm(keyword_arr, desc=\"WIKTIONARY DEFINITION GENERATION\"):\n",
    "        count += 1\n",
    "        if kw[0].lower() not in [kw[0].lower() for kw in final]:\n",
    "            for pos in kw[1]:\n",
    "\n",
    "                temp_def = wikt_def_predict.driver(title.strip(), clean_text.strip(), kw[0].strip(), pos.strip(),0)\n",
    "                \n",
    "                if temp_def!='invalid-pos' and temp_def!='invalid-term':\n",
    "                    final.append([kw[0],temp_def.replace('invalid-pos','').replace('invalid-term','')])\n",
    "                    break\n",
    "                             \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_def_refs(orig_text, keywords_only):\n",
    "    indexes = []\n",
    "    index_sum = 0\n",
    "    for kw in keywords_only:\n",
    "        temp_index = orig_text[index_sum:].lower().find(kw.lower() + ' ') + len(kw)\n",
    "        index_sum += temp_index\n",
    "        indexes.append(index_sum)\n",
    "    \n",
    "    ref_text = orig_text\n",
    "    index_adjust = 0\n",
    "    for i in range(len(indexes)):\n",
    "        ref_text = ref_text[:indexes[i]+index_adjust] + '|{}|'.format(i+1) + ref_text[indexes[i]+index_adjust:]\n",
    "        index_adjust += len(str(i+1)) + 2\n",
    "        \n",
    "    return ref_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_final_doc(corpus_obj):\n",
    "    final_doc = '===GLOGEN GLOSSARY===\\n\\n'\n",
    "    \n",
    "    def_count = 0\n",
    "    for definition in corpus_obj['glossary']:\n",
    "        def_count += 1\n",
    "        temp_sent = definition[1]\n",
    "        final_doc += '|{}| '.format(def_count) + definition[0] + ' : ' + (temp_sent + '.').replace('..','') + '\\n'\n",
    "        \n",
    "    final_doc += '\\n===DOCUMENT BODY===\\n\\n' + corpus_obj['text_w_ref']\n",
    "    \n",
    "    return final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(pyfiglet.figlet_format(\"DAIC GLOGEN\"),)\n",
    "# print('DESCRIPTION: GLOGEN automatically generates glossaries and prepends them to given .txt files. \\nENSURE: <filename>.txt == original text title.')\n",
    "# answer = ''\n",
    "# txt_address = ''\n",
    "# while True:\n",
    "#     answer = input('\\nType \"yes\" / \"no\" to starting GLOGEN:\\n>>>')\n",
    "#     if answer.lower().startswith(\"y\"):\n",
    "#         txt_address += input('Type address where .txt files are stored. If same address as main.py press ENTER.\\n>>>')\n",
    "#         break\n",
    "#     elif answer.lower().startswith(\"n\"):\n",
    "#         exit()\n",
    "#     else:\n",
    "#         print('INVALID INPUT --- TRY AGAIN.')\n",
    "#         continue\n",
    "# if txt_address == '':\n",
    "#     txt_address = os.getcwd()\n",
    "txt_address = '/home/jackragless/projects/github/DAIC_GLOGEN/text_files'\n",
    "if txt_address[-1] == '/':\n",
    "    txt_address = txt_address[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOC 1/11 --- Ascendency.txt\n",
      "\n",
      "AI KEYWORD PREDICTION:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23c62e08aa244f19aac9854ef049f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b11099379a94ea0ac4562d1e199ead8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WIKTIONARY DEFINITION GENERATION: 100%|██████████| 11/11 [00:23<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOGEN DOC ADDED.\n",
      "\n",
      "DOC 2/11 --- Anti-information.txt\n",
      "\n",
      "AI KEYWORD PREDICTION:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69596d7bc98046719fa81e5ad22b2698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5680332f5e4ea38f63d9689c6cb40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WIKTIONARY DEFINITION GENERATION: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOGEN DOC ADDED.\n",
      "\n",
      "DOC 3/11 --- Asymptotic equipartition property.txt\n",
      "\n",
      "AI KEYWORD PREDICTION:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35da36cf36574f7fa85e3b561c7a8fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d656e62dbf014323ae9f73783aad2977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WIKTIONARY DEFINITION GENERATION:  86%|████████▋ | 19/22 [00:59<00:09,  3.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-8d0e5dea8eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mkeywords_and_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchink_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mglossary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_definitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords_and_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mkeywords_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglossary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-e8ebe3d2027c>\u001b[0m in \u001b[0;36mgenerate_definitions\u001b[0;34m(title, clean_text, keyword_arr)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mtemp_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikt_def_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtemp_def\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'invalid-pos'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtemp_def\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'invalid-term'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/github/DAIC_GLOGEN/wikt_def_predict.ipynb\u001b[0m in \u001b[0;36mdriver\u001b[0;34m(title, curtext, kw, pos, depth)\u001b[0m\n",
      "\u001b[0;32m~/projects/github/DAIC_GLOGEN/wikt_def_parse.ipynb\u001b[0m in \u001b[0;36mdefine\u001b[0;34m(kw)\u001b[0m\n",
      "\u001b[0;32m~/projects/github/DAIC_GLOGEN/wikt_def_parse.ipynb\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, word, language)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<!--\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_comment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/html/parser.py\u001b[0m in \u001b[0;36mparse_endtag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgtpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_cdata_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgtpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_endtag\u001b[0;34m(self, name, check_already_closed)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malready_closed_empty_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_endtag\u001b[0;34m(self, name, nsprefix)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \"\"\"\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#print(\"End tag: \" + name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popToTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mendData\u001b[0;34m(self, containerClass)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontainerClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_was_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobject_was_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_recent_element\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mobject_was_parsed\u001b[0;34m(self, o, parent, most_recent_element)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;31m# Check if we are inserting into an already parsed node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(txt_address + '/GLOGEN') == False:\n",
    "    os.mkdir(txt_address + '/GLOGEN')\n",
    "\n",
    "for i,filename in enumerate(os.listdir(txt_address)):\n",
    "    \n",
    "    if filename.endswith('.txt'):\n",
    "        \n",
    "        print('DOC',str(i+1)+'/'+str(len(os.listdir(txt_address))), '---', filename)\n",
    "        orig_text = open(txt_address+'/'+filename).read()\n",
    "        processed = preprocess_utils.clean_text(orig_text, False,False,True,False,False)\n",
    "        \n",
    "        print('\\nAI KEYWORD PREDICTION:')\n",
    "        keywords_and_pos = chink_utils.keywords(generate_keywords(processed))\n",
    "        \n",
    "        glossary = generate_definitions(filename[:-4], processed, keywords_and_pos)\n",
    "        \n",
    "        keywords_only = [obj[0] for obj in glossary]\n",
    "        text_w_ref = add_def_refs(orig_text, keywords_only)\n",
    "        \n",
    "        temp_obj = {\n",
    "          'title':filename[:-4], \n",
    "          'text_w_ref':add_def_refs(orig_text, keywords_only), \n",
    "          'glossary': glossary\n",
    "         }\n",
    "        text_file = open(txt_address + \"/GLOGEN/{}.txt\".format(temp_obj['title']), \"w\")\n",
    "        text_file.write( gen_final_doc(temp_obj) )\n",
    "        text_file.close()\n",
    "        print('GLOGEN DOC ADDED.\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
